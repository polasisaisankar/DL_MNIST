{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3c454c",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3b75cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Flatten,MaxPool2D,Dense\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a11f1e",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edb1533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e976e27a",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb83b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f3c2a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56091096",
   "metadata": {},
   "source": [
    "## build architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba41d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sireeshapolasi/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(6,(3,3),activation='relu'))\n",
    "model.add(Conv2D(6,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten(input_shape=(32,32,3)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ad870",
   "metadata": {},
   "source": [
    "## compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f479623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e6e0f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53071882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1938 - loss: 9.5726\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3448 - loss: 1.8411\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4452 - loss: 1.5553\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5244 - loss: 1.3402\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5850 - loss: 1.1845\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 1.0383\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.9090\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.8049\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7535 - loss: 0.7111\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7844 - loss: 0.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13474f0b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb4c1",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ae5b1",
   "metadata": {},
   "source": [
    " Analysis : in the previous experiment,it is observed that accuracy is improved continuously for every epoch .\n",
    "\n",
    " So, continue the training process by increasing the epochs from 10 - 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca7e5f",
   "metadata": {},
   "source": [
    "Hyperperameters:\n",
    "        epochs : 30\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2bb9bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sireeshapolasi/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1218 - loss: 18.8627\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1021 - loss: 2.3027\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1418 - loss: 2.2386\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1716 - loss: 2.1363\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1885 - loss: 2.0711\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2073 - loss: 1.9874\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2169 - loss: 1.9329\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2777 - loss: 1.7914\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2886 - loss: 1.7575\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2980 - loss: 1.7284\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3062 - loss: 1.7075\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3089 - loss: 1.7000\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3111 - loss: 1.6926\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3157 - loss: 1.6829\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3231 - loss: 1.6703\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3188 - loss: 1.6736\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3286 - loss: 1.6630\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3215 - loss: 1.6496\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3566 - loss: 1.6164\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3852 - loss: 1.5833\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3980 - loss: 1.5598\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4032 - loss: 1.5500\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4060 - loss: 1.5367\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4128 - loss: 1.5367\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4125 - loss: 1.5332\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4180 - loss: 1.5180\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4145 - loss: 1.5237\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4202 - loss: 1.5143\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4178 - loss: 1.5140\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4195 - loss: 1.5087\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4224 - loss: 1.5039\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4223 - loss: 1.5043\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4243 - loss: 1.4978\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4254 - loss: 1.4955\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4413 - loss: 1.4754\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4565 - loss: 1.4573\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4646 - loss: 1.4415\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4652 - loss: 1.4407\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4689 - loss: 1.4291\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4709 - loss: 1.4241\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4806 - loss: 1.4037\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4820 - loss: 1.4050\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4772 - loss: 1.4116\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4781 - loss: 1.3996\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4860 - loss: 1.3998\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4899 - loss: 1.3918\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4958 - loss: 1.3702\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5019 - loss: 1.3630\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5071 - loss: 1.3518\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5063 - loss: 1.3578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16af8b350>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(6,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten(input_shape=(32,32,3)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train,epochs=50,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575abc0e",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add58931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sireeshapolasi/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.1582 - loss: 10.8504 - val_accuracy: 0.2915 - val_loss: 1.9671\n",
      "Epoch 2/60\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.3051 - loss: 1.9194 - val_accuracy: 0.3460 - val_loss: 1.7989\n",
      "Epoch 3/60\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.3745 - loss: 1.7246 - val_accuracy: 0.4085 - val_loss: 1.6410\n",
      "Epoch 4/60\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4275 - loss: 1.5753 - val_accuracy: 0.4461 - val_loss: 1.5303\n",
      "Epoch 5/60\n",
      "\u001b[1m283/782\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4685 - loss: 1.4622"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m model.add(Dense(\u001b[32m10\u001b[39m,activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     12\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DL_LAB/venv_cifar/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(6,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten(input_shape=(32,32,3)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "result = model.fit(x_train,y_train,epochs=60,batch_size=64,validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5ddd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('accuracy', [0.2567799985408783, 0.4290600121021271, 0.516319990158081, 0.5722200274467468, 0.6173400282859802, 0.6577799916267395, 0.6953799724578857, 0.7265400290489197, 0.7570000290870667, 0.7846400141716003, 0.8076199889183044, 0.8281800150871277, 0.8471199870109558, 0.857479989528656, 0.8718799948692322, 0.8803600072860718, 0.8897200226783752, 0.8966000080108643, 0.9044399857521057, 0.9123600125312805, 0.916700005531311, 0.9166600108146667, 0.9267399907112122, 0.9297000169754028, 0.9315999746322632, 0.9294599890708923, 0.9397799968719482, 0.9343000054359436, 0.9396799802780151, 0.9356399774551392, 0.9519400000572205, 0.9498599767684937, 0.9385600090026855, 0.9427599906921387, 0.9570199847221375, 0.9565399885177612, 0.9519400000572205, 0.9476600289344788, 0.9563999772071838, 0.9564800262451172, 0.9576600193977356, 0.9549999833106995, 0.9630399942398071, 0.9571599960327148, 0.9615399837493896, 0.9637200236320496, 0.9621400237083435, 0.9601399898529053, 0.9663800001144409, 0.9647200107574463, 0.9606000185012817, 0.9634799957275391, 0.9695199728012085, 0.9617199897766113, 0.9643800258636475, 0.9646199941635132, 0.9704599976539612, 0.9702399969100952, 0.9633600115776062, 0.9695199728012085]), ('loss', [2.552049398422241, 1.6130424737930298, 1.3742567300796509, 1.2126071453094482, 1.0829405784606934, 0.9660735130310059, 0.8603911995887756, 0.7719865441322327, 0.6867882013320923, 0.6119770407676697, 0.5465920567512512, 0.4828979969024658, 0.4398810565471649, 0.40247344970703125, 0.3648828864097595, 0.3408522307872772, 0.3147379755973816, 0.29663383960723877, 0.2758471369743347, 0.25674259662628174, 0.2429978847503662, 0.24422335624694824, 0.2155885547399521, 0.20824001729488373, 0.20452435314655304, 0.2134125977754593, 0.18169042468070984, 0.19649405777454376, 0.18307289481163025, 0.19657105207443237, 0.1439911127090454, 0.15206177532672882, 0.18907417356967926, 0.17641466856002808, 0.1294960081577301, 0.13443313539028168, 0.14821256697177887, 0.1667073369026184, 0.13265611231327057, 0.13679730892181396, 0.13492123782634735, 0.13975848257541656, 0.11819403618574142, 0.1339084655046463, 0.12070147693157196, 0.11828378587961197, 0.1226268857717514, 0.1253751516342163, 0.1032097190618515, 0.11080620437860489, 0.13175222277641296, 0.11774018406867981, 0.09922067075967789, 0.12121415883302689, 0.11897850781679153, 0.11391445249319077, 0.09510388970375061, 0.0966755673289299, 0.12302693724632263, 0.1027882844209671])])\n"
     ]
    }
   ],
   "source": [
    "print(result.history.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95ac837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print(result.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86d246",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1a62c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.plot(result.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m],label=\u001b[33m'\u001b[39m\u001b[33mtrain accuracy\u001b[39m\u001b[33m'\u001b[39m,color = \u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,label=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, color = \u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.legend()\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mtrain vs validation accuracy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result.history['accuracy'],label='train accuracy',color = 'blue')\n",
    "plt.plot(result.history['val_accuracy'],label='val_accuracy', color = 'red')\n",
    "plt.legend()\n",
    "plt.title('train vs validation accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
